{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TWFE Difference-in-Differences Regression\n",
    "\n",
    "## Objective\n",
    "\n",
    "This notebook estimates causal lift using Two-Way Fixed Effects (TWFE) Difference-in-Differences regression on the purchase-based panel.\n",
    "\n",
    "**What TWFE estimates:**\n",
    "TWFE regression pools across campaigns to estimate an average treatment effect (ATE) while controlling for:\n",
    "- Household-level fixed effects (time-invariant household characteristics)\n",
    "- Week-level fixed effects (aggregate time-varying confounds)\n",
    "\n",
    "**Why regression instead of per-campaign 2x2 means:**\n",
    "With 20 campaigns, many have incomplete 2x2 structures (missing treated-control or pre-post cells). TWFE pools data across campaigns and time periods to estimate a pooled ATE even when campaign-level 2x2 is sparse.\n",
    "\n",
    "**Inputs:**\n",
    "- `data/intermediate/did_campaign_panel_purchase.parquet`\n",
    "- `did_campaign_estimates_purchase.parquet`, `did_campaign_estimates_purchase_valid.parquet`, `did_campaign_estimates_purchase_invalid.parquet`, `did_overall_estimate_purchase.parquet`\n",
    "\n",
    "**Outputs:**\n",
    "- Summary tables (JSON, CSV)\n",
    "- Model coefficients (CSV)\n",
    "- Diagnostics report (TXT)\n",
    "- Figures (PNG) in `results/modeling/figures/`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment & Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /Users/rajnishpanwar/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f\"Python executable: {sys.executable}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 18:01:33,785 - INFO - Repository root: /Users/rajnishpanwar/Desktop/Casual Analytics\n"
     ]
    }
   ],
   "source": [
    "def find_repo_root(start: Path) -> Path:\n",
    "    p = start.resolve()\n",
    "    for _ in range(12):\n",
    "        if (p / \"README.md\").exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    raise RuntimeError(\"Repository root not found (README.md missing)\")\n",
    "\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "DATA_DIR = REPO_ROOT / \"data\" / \"intermediate\"\n",
    "OUT_DIR = REPO_ROOT / \"results\" / \"modeling\"\n",
    "FIG_DIR = OUT_DIR / \"figures\"\n",
    "RUN_MANIFESTS_DIR = REPO_ROOT / \"results\" / \"run_manifests\"\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RUN_MANIFESTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger.info(f\"Repository root: {REPO_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 18:01:33,821 - INFO - Loaded panel: 122536 rows, 11 columns\n"
     ]
    }
   ],
   "source": [
    "panel_file = DATA_DIR / \"did_campaign_panel_purchase.parquet\"\n",
    "if not panel_file.exists():\n",
    "    raise FileNotFoundError(f\"Panel file not found: {panel_file}\")\n",
    "\n",
    "df_panel = pd.read_parquet(panel_file)\n",
    "logger.info(f\"Loaded panel: {len(df_panel)} rows, {len(df_panel.columns)} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Gates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 18:01:33,854 - INFO - Summary: 122536 rows, 30 households, 1584 campaigns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2x2 Structure (treated x post, rows):\n",
      "post         0      1     All\n",
      "treated                      \n",
      "0        57256  64413  121669\n",
      "1          408    459     867\n",
      "All      57664  64872  122536\n"
     ]
    }
   ],
   "source": [
    "required_cols = [\"campaign_id\", \"household_id\", \"week_number\", \"treated\", \"post\", \"total_sales_value\", \"total_units\"]\n",
    "missing_cols = [col for col in required_cols if col not in df_panel.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "df_panel[\"treated\"] = df_panel[\"treated\"].astype(int)\n",
    "df_panel[\"post\"] = df_panel[\"post\"].astype(int)\n",
    "\n",
    "df_panel[\"did\"] = df_panel[\"treated\"] * df_panel[\"post\"]\n",
    "\n",
    "df_panel[\"y_sales\"] = pd.to_numeric(df_panel[\"total_sales_value\"], errors=\"coerce\")\n",
    "df_panel[\"y_units\"] = pd.to_numeric(df_panel[\"total_units\"], errors=\"coerce\")\n",
    "df_panel[\"y_log_sales\"] = np.log1p(np.maximum(df_panel[\"total_sales_value\"], 0))\n",
    "\n",
    "treated_post_crosstab = pd.crosstab(df_panel[\"treated\"], df_panel[\"post\"], margins=True)\n",
    "print(\"2x2 Structure (treated x post, rows):\")\n",
    "print(treated_post_crosstab)\n",
    "\n",
    "n_rows = len(df_panel)\n",
    "n_households = df_panel[\"household_id\"].nunique()\n",
    "n_campaigns = df_panel[\"campaign_id\"].nunique()\n",
    "\n",
    "logger.info(f\"Summary: {n_rows} rows, {n_households} households, {n_campaigns} campaigns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Sales values can be negative due to discounts/returns. For log transformation, we shift by the minimum value so all values are non-negative before applying log1p.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_twfe(df: pd.DataFrame, outcome_col: str, cluster_col: str = \"household_id\"):\n",
    "    y = df[outcome_col].values\n",
    "    \n",
    "    X_did = pd.DataFrame({\"did\": df[\"did\"].astype(float)})\n",
    "    X_hh = pd.get_dummies(df[\"household_id\"], prefix=\"hh\", drop_first=True, dtype=float)\n",
    "    X_week = pd.get_dummies(df[\"week_number\"], prefix=\"week\", drop_first=True, dtype=float)\n",
    "    \n",
    "    X = pd.concat([X_did, X_hh, X_week], axis=1)\n",
    "    X = add_constant(X, prepend=False)\n",
    "    X = X.astype(float)\n",
    "    \n",
    "    param_names = X.columns.tolist()\n",
    "    \n",
    "    model = OLS(y, X)\n",
    "    result = model.fit(cov_type=\"cluster\", cov_kwds={\"groups\": df[cluster_col]})\n",
    "    \n",
    "    result.param_names = param_names\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Plan\n",
    "\n",
    "Fit TWFE DiD models with household and week fixed effects:\n",
    "- Model A: y_sales ~ did + C(household_id) + C(week_number)\n",
    "- Model B: y_log_sales ~ did + C(household_id) + C(week_number)\n",
    "- Model C: y_units ~ did + C(household_id) + C(week_number)\n",
    "\n",
    "Standard errors: clustered at household_id level. Also compute robust HC1 standard errors for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 18:01:33,871 - INFO - Fitting model for y_sales\n",
      "2026-01-14 18:01:34,811 - INFO -   R²: 0.3296, N: 122536.0\n",
      "2026-01-14 18:01:34,812 - INFO - Fitting model for y_log_sales\n",
      "2026-01-14 18:01:35,881 - INFO -   R²: 0.3717, N: 122536.0\n",
      "2026-01-14 18:01:35,881 - INFO - Fitting model for y_units\n",
      "2026-01-14 18:01:36,787 - INFO -   R²: 0.2433, N: 122536.0\n",
      "2026-01-14 18:01:36,788 - INFO - All models fitted\n"
     ]
    }
   ],
   "source": [
    "models: Dict[str, object] = {}\n",
    "outcomes = [\"y_sales\", \"y_log_sales\", \"y_units\"]\n",
    "\n",
    "for outcome in outcomes:\n",
    "    logger.info(f\"Fitting model for {outcome}\")\n",
    "    result = run_twfe(df_panel, outcome)\n",
    "    models[outcome] = result\n",
    "    logger.info(f\"  R²: {result.rsquared:.4f}, N: {result.nobs}\")\n",
    "\n",
    "logger.info(\"All models fitted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajnishpanwar/.venv/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1884: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(np.diag(self.cov_params()))\n",
      "/Users/rajnishpanwar/.venv/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1884: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(np.diag(self.cov_params()))\n",
      "/Users/rajnishpanwar/.venv/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1884: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(np.diag(self.cov_params()))\n",
      "2026-01-14 18:01:36,809 - INFO - Outputs saved to /Users/rajnishpanwar/Desktop/Casual Analytics/results/modeling\n"
     ]
    }
   ],
   "source": [
    "results_summary = []\n",
    "for outcome in outcomes:\n",
    "    result = models[outcome]\n",
    "    \n",
    "    if hasattr(result, 'param_names') and \"did\" in result.param_names:\n",
    "        did_idx = result.param_names.index(\"did\")\n",
    "        did_coef = result.params.iloc[did_idx]\n",
    "        did_se = result.bse.iloc[did_idx]\n",
    "        did_pval = result.pvalues.iloc[did_idx]\n",
    "        ci = result.conf_int().iloc[did_idx]\n",
    "        ci_low, ci_high = ci[0], ci[1]\n",
    "    elif hasattr(result.params, 'index') and \"did\" in result.params.index:\n",
    "        did_coef = result.params[\"did\"]\n",
    "        did_se = result.bse[\"did\"]\n",
    "        did_pval = result.pvalues[\"did\"]\n",
    "        ci = result.conf_int().loc[\"did\"]\n",
    "        ci_low, ci_high = ci[0], ci[1]\n",
    "    else:\n",
    "        did_coef = 0\n",
    "        did_se = np.nan\n",
    "        did_pval = 1.0\n",
    "        ci_low, ci_high = np.nan, np.nan\n",
    "    \n",
    "    results_summary.append({\n",
    "        \"outcome\": outcome.replace(\"y_\", \"\"),\n",
    "        \"coef\": float(did_coef),\n",
    "        \"se_clustered\": float(did_se),\n",
    "        \"pvalue\": float(did_pval),\n",
    "        \"ci_low\": float(ci_low),\n",
    "        \"ci_high\": float(ci_high),\n",
    "        \"nobs\": int(result.nobs),\n",
    "        \"n_households\": n_households\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results_summary)\n",
    "df_results.to_csv(OUT_DIR / \"twfe_did_summary.csv\", index=False)\n",
    "\n",
    "result_sales = models[\"y_sales\"]\n",
    "if hasattr(result_sales, 'param_names'):\n",
    "    df_coefs = pd.DataFrame({\"param\": result_sales.param_names, \"coefficient\": result_sales.params.values})\n",
    "elif hasattr(result_sales.params, 'index'):\n",
    "    df_coefs = pd.DataFrame({\"param\": result_sales.params.index, \"coefficient\": result_sales.params.values})\n",
    "else:\n",
    "    df_coefs = pd.DataFrame({\"param\": range(len(result_sales.params)), \"coefficient\": result_sales.params})\n",
    "df_coefs.to_csv(OUT_DIR / \"twfe_coefficients.csv\", index=False)\n",
    "\n",
    "logger.info(f\"Outputs saved to {OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Manifest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 18:01:36,815 - INFO - Manifest saved to /Users/rajnishpanwar/Desktop/Casual Analytics/results/run_manifests/twfe_manifest_20260114_180136.json\n"
     ]
    }
   ],
   "source": [
    "def get_package_versions() -> Dict[str, str]:\n",
    "    versions = {}\n",
    "    for pkg in [\"pandas\", \"numpy\", \"statsmodels\"]:\n",
    "        try:\n",
    "            mod = __import__(pkg)\n",
    "            versions[pkg] = getattr(mod, \"__version__\", \"unknown\")\n",
    "        except ImportError:\n",
    "            versions[pkg] = \"not_installed\"\n",
    "    return versions\n",
    "\n",
    "\n",
    "manifest = {\n",
    "    \"timestamp_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"input_parquet\": str(panel_file),\n",
    "    \"output_files\": [\n",
    "        str(OUT_DIR / \"twfe_did_summary.csv\"),\n",
    "        str(OUT_DIR / \"twfe_coefficients.csv\")\n",
    "    ],\n",
    "    \"n_rows\": n_rows,\n",
    "    \"n_households\": n_households,\n",
    "    \"n_campaigns\": n_campaigns,\n",
    "    \"package_versions\": get_package_versions(),\n",
    "    \"python_executable\": sys.executable\n",
    "}\n",
    "\n",
    "manifest_path = RUN_MANIFESTS_DIR / f\"twfe_manifest_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\n",
    "logger.info(f\"Manifest saved to {manifest_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Notebook 03**: Event study regression (leads/lags) to test parallel trends assumption\n",
    "- **Notebook 04**: Uplift modeling (T-learner / X-learner style) for heterogeneous treatment effects\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (causal_analytics)",
   "language": "python",
   "name": "causal_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
